ЭТО БУФЕР ДАНИ
НЕ СРАТЬ СЮДА

*Средний случай*

/ Элементраное усреднение:
$ T_"ср" (n) = (T_a^or (n) + T_A^and (n))/2 = 6n - 3 $

/ Вероятностный подход:

- Переприсваивание максимума при просмотре $k$-го элемента происходит, если в подмассиве из первых к элементов максимальным элементом является последний. В случае равномерного распределения вероятность этого равна $1/k$. Тогда в массиве из $n$ элементов математическое ожидание среднего количества операций присваивания определяется как:

$ limits(sum)_(k = 1)^N 1/k = H n approx ln(N) + gamma, gamma approx 0,057, " где " gamma #[ --- постоянная Эйлера]  $

$ gamma = limits(lim)_(n -> infinity) (limits(sum)_(k = 1)^n - ln n) = limits(lim)_(n -> infinity) (1 + 1/2 + 1/3 + dots + 1/n - ln n) $

Величина $H_n$ называется $n$-ым гармоническим числом.

$ overline(T)_a (n) = 2 + 1 + 3(n - 1) + 2(n - 1) + 2(ln n + gamma)) = 5 n - 2 + 2 ln n + 2 gamma $


#grid(columns: 2,
$log_B 1 = 0$, $limits(sum)_(i = 1)^N C_i = C limits(sum)_(i = 1)^N i$,
$log_B B = 1$, $limits(sum)_(i = L)^N i = limits(sum)_(i = 0)^(N - L) (i + L)$,
$log_B (X Y) = log_B X + log_B Y$, $limits(sum)_(i = L)^N i = limits(sum)_(i = 0)^N i- limits(sum)_(i = 0)^(L - 1) i$,
$log_B X^Y = Y log_B X$, $limits(sum)_(i = 1)^N (A + B) = limits(sum)_(i = 1)^N A + limits(sum)_(i = 1)^N B$,
$log_A X = (log_B X)/(log_B A)$, $limits(sum)_(i = 0)^N (N - i) = limits(sum)_(i = 0)^N i$,
$A^(log_B C) = C^(log_B A)$,
$log_A B = 1/(log_B A)$,
)

Очень пригодится в области анализа алгоритмов умение распознавать два основных класса формул суммирования:
- *Арифметические прогрессии*. Арифметическую прогрессию в виде формулы $S(n) = limits(sum)_i^n i = n (n + 1)/2$ можно встретить в анализе алгоритма сортировки методом выбора. По большому счёту, важным фактом являеется наличие квадратичной суммы, а не то, что константа равняется $1/2$. В общем, для $p >= 1$:

$ S(n, p) = limits(sum)_i^n i^p = Theta (n^(p + 1)) $

Для $p < -1$ эта сумма всегда стремится к константе, даже когда $n -> infinity$.

- *Геометрическая прогрессия*. В геометрических прогрессиях индекс цикла играет роль показателя степени, то есть:

$ G(n, a) = limits(sum_(i = 0)^n) a' = a(a^(n + 1) - 1)/(a - 1) $

Сумма прогрессии зависит от её знаменателя, то есть числа $a$. При $a < 1$ эта сумма стремится к константе, даже когда $n -> infinity$.

*Пример анализа сортировки вставкми*:

#table(columns: 3,
	table.header([*Сортировка вставками*], [*Стоимость*], [*Количество повторений*]),,
	table.cell(rowspan: 9, ```cpp
	for(i = 1; i < n; ++i) {
		x = a[i];
		j = i - 1;
		while(j >= 0 && a[j] > x) {
			a[j + 1] = a[j];
			j--;
		}
		a[j + 1] = x;
	}
	```),
	$c_1$,$c_2$,$c_3$,$c_4$,$c_5$,$c_6$,[],$c_7$,$c_8$,
	$n$, $n -1$, $n-1$, $limits(sum)_(i = 1)^(n -1) t_i$, table.cell(rowspan:2, $limits(sum)_(i = 1)^(n - 1) (t_i - 1)$), [], $n - 1$
)

где $t_i$ --- количество повторений цикла ```cpp while```.

Время работы алгоритма сортировки вставками --- это сумма времён работы каждого шага.

$ T(n) = c_1 n + c_2 (n - 1) + c_3 (n - 1) + c_4 limits(sum)_(i = 1)^(n - 1) t_i + c_5 limits(sum)_(i = 1)^(n - 1) (t_i - 1) + c_6 limits(sum)_(i = 1)^(n - 1) (t_i - 1) + c_7 (n - 1) $

=== Анализ среднего случая
Характер поведения усреднённого времени работы часто ничем не лучше поведения времени работы для наихудшего случая. Предположим, что последовательность, к которой применяется сортировка методом вставок, сформирована случайным образом. Сколько времени понадобится, чтобы определить, в какое место подмассива ```cpp a[0..i-1]``` следует поместить элемент ```cpp a[i]```? Предположим, что в среднем половина элементов этого подмассива меньше, чем ```cpp a[i]```, а половина — больше его. Таким образом, в среднем нужно проверить половину элементов подмассива ```cpp a[0..i-1]```, поэтому $t_i approx i/2$.

$ limits(sum)_(i = 1)^(n - 1) i/2 = (n(n - 1))/4 $

$ limits(sum)_(i = 1)^(n - 1) (i - 1)/2 = (n(n - 3))/4 + 1/2 $

$ T(n) = c_1 n + c_2 (n - 1) + c_3 (n - 1) + c_4 (n(n - 1))/4 + c_5 ((n(n - 3))/4 + 1/2) + \
c_6 ((n (n - 3))/4 + 1/2) +c_7 (n - 1) = \
((c_4)/4 + (c_5)/4 + (c_6) / 4) n^2 + (c_1 + c_2 + c_3 - (c_4)/4 - (3 c_5)/4 - (3 c_6)/4 c_7)n - (c_2 + c_3 - (c_5)/2 - (c_6)/2 + c_7) $

В результате получается, что среднее время работы алгоритма является квадратичной функицей от количества входных элементов, то есть характер этой зависимоститакой же, как и для времени работы в наихудшем случае.

Для облегченияанализа алгоритма были сделаны некоторые упрощения. Было проигнориорвоано фактическое время выподлнения каждой инструкции. Эта величина была представлена в виде некоторой константы $c_i$. Далее эти константы также были обобщены и время работы алгоритма выражается просто формулой: $a n^2 + b n + c$, где $a$, $b$ и $c$ --- некоторые константы, зависящие от стоимостей $c_i$.

Таким образом, игнорируются не только фактические стоимости команд, но и их абстрактные стоимости $c_i$.
















Пусть $T_1 (n)$ и $T_2 (n)$ --- время выполнения двух вложенных фрагментов программы $P_1$ и $P_2$ соответственно. Пусть $T_1 (n) = O(f(n))$, $T_2 (n) = O(g(n))$. Тогда $T_1 (n) dot T_2 (n) = O(f(n) dot g(n))$.

*Доказательство*:

$T_1 (n) = O(f(n)) => exists c_1 eq.triple const, n_1 in NN space space forall n >= n_1 space T_1 (n) <= c_1 dot f(n)$

$T_2 (n) = O(g(n)) => exists c_2 eq.triple const, n_1 in NN space space forall n >= n_2 space T_2 (n) <= c_2 dot g(n)$

Пусть $n_0 = max(n_1, n_2)$. Если $n >= n_0$, то очевидно:

$T_1 (n) dot T_2 (n) <= c_1 dot f(n) dot c_2 g(n) => T_1 (n) dot T_2 (n) <= (c_1 dot c_2) dot (f(n) dot g(n)) $

*Следствие*:

$O(c dot f(n)) approx O(f(n))$, если $c > 0$.

$O((n^2)/2) = O(n^2)$, то есть постоянным множителем, в силу правила произведений, можно пренебречь.


#table(columns: 3,
	table.header([*Сортировка вставками*], [*Стоимость*], [*Количество повторений*]),,
	table.cell(rowspan: 9, ```cpp
	for(i = 1; i < n; ++i) {
		x = a[i];
		j = i - 1;
		while(j >= 0 && a[j] > x) {
			a[j + 1] = a[j];
			j--;
		}
		a[j + 1] = x;
	}
	```),
	$c_1$,$c_2$,$c_3$,$c_4$,$c_5$,$c_6$,[],$c_7$,$c_8$,
	$n$, $1$, $1$, $i$, $1$, $1$,[], $1$
)

Наибольшее количество работы алгоритм произведёт, когда всякий новый элемент добавляется в начало отсортированного списка. Такое возможно только если элементы исходного списка идут в убывающем порядке. В этмо случае $i$й вставлемый элемент сравнивается с $i$ предыдущими, и этот процесс повторяется $n - 1$ раз. Таким, образом, операторы в строках 5-6 имеют порядок $O(1)$ (правило сложения), внутренний цикл ```cpp while``` выполняется $i$ раз, поэтому, по правилу произведений, общее время выполнения этого цикла имеет порядок $O(i) dot 1$, что равно $O(i)$. Для операторов внутри цикла ```cpp for``` время выполнения на каждой итерации этого внешнего цикла ```cpp for``` определяется по правилу суммы $O(max(1, 1, i, 1)) = O(i)$.

Цикл выполняется $n - 1$ раз, поэтому суммарное время выполнения программы ограничено сверху выражением $limits(sum)_(i = 1)^(n - 1) i  = (n(n - 1))/2 = (n^2)/2 - n/2$, которое имеет порядок $O(n^2)$.





























У нас элементарный исход имеет следующий вид:

$
  vec(omega) = (0,0,dots,0,1)
$

Построим ряд распределений случайной величины.

Какой должен быть наш правильный взгляд на эти геометрические распределение? По пуассонскому закону нельзя, оценки будут неверные. Если не подходит ни то, ни другое, то нужно искать другую модель --- про все дискретные распределения не расскажешь, их много.

Стохастический эксперимент соответствует классическому вероятностному пространству. Что это означает? Все исходы равновозможны и их конечное число.

Давайте тогда посмотрим, какой содержательный смысл у $xi$


Гипергеометрические и отрицбкном распределения, см. Ширяев

Если кому-то проще воспринимать тервер на языке иронии, то есть такой автор как Тутубалин

// Я и без Тутубалина уже совсем Туту.

Напомним себе, что случайная величина называется абсолютно непрерывной, если $exists f(x) >= 0 space F_xi (x) = limits(integral)_(-infinity)^x f(t) dif t$.

$limits(integral)_(-infinity)^infinity f(x) dif x = 1$

_Важное примечание: нужно писать в тетради так, чтобы строчные буквы от заглавных визуально отличались, иначе Нина Юрьевна за себя не отвечает_

Мы думаем, что по условию эксперимента $f(x)$ должна быть такой:

$c x |_a^b = c(b - a) = 1 => c = 1/(b - a)$

При $x <= a$ $F(x) = limits(integral)_(-infinity)^x $

== Замыкание по пересечению

*Теорема*. Если L и M – регулярные языки, то таковым
будет язык $L inter M$.

*Доказательство*:

Пусть $A$ и $B$ – КДА, определяющие языки
$L$ и $M$, соотвественно.

Построим автомат $C$ – произведение автоматов A и B.

Сделаем финальными состояниями C пары, состоящие из
финальных состояний $A$ и $B$.

Очевидно, что данный автомат будет принимать только те слова, которые принадлежат $L$ и $M$, т. е. $L inter M$.



_Когда мы говори о дополнении, мы должны оговаривать, до чего мы дополняем. В качестве универсального языка мы используем множество всех слов в афлавите $Sigma$. Это регулярный язык. Если $L$ --- тоже регулярный язык, то дополнение --- это $Sigma^* - L$._

_Мы только что выяснили, что операция вычитания регулярного языка из регулярного языка даёт нам регулярный язык._



_Мы берём сумму регулярных выражений. Замыкание --- самая сильная операция, поэтому выполняем её прежде других операций._

_Теперь немножко посложнее, поэтому здесь потребуется напряжение мысли. Как работает инверсный (обратный) гомоморфизм? В его результате получается новый язык, где строки одного алфавита заменяются строками другого алфавита_

_Пусть  на выходе гомоморфизма $h(limits(dots)_arrow.t) = L$_

_Вот чтобы найти язык $dots$ (обозначим его за $M$) и существует обратный гомоморфизм: $h^(-1) (L) = M$_

_По строке $a b a b$ мы в целом смогли восстановить исходный язык. А вот попытка восстановить $b a b a$ не увенчается успехом, поэтому мы просто игнорируем её: на нет и суда нет._




Основа доказательства: $w$ переводит автомат $B$ из начального состояния в состояние $p$ тогда и только тогда, когда $h(w)$ переводит автомат $A$ из начального в то же стстояние $p$.


*Определене*.
/ Краевая задача: --- задача нахождения решения @l8:eq1, удовлетворяющего заданным краевым условиям @l8:eq3

Мы что-то знаем о решении в точке $a$ (согласно первому уравнению системы) и что-то знаем о решении в точке $b$ (согласно второму уравнению системы).

*Примеры*.

1. $cases(
	y'' = 0\, 0 <= x <= 1,
	y(0) = 0, y(1) = 0
)$

Тут легко найти общее решение уравнения, дважды проинтегрировав:

$y = c_1 x + c_2$

Подставляем в краевые условия:

$y(0) = c_2 = 0 \
y(1) = c_1 + underbrace(c_2, = 0) = 0 => c_1 = 0$

Следовательно, $y(x) eq.triple 0$ --- единственное решение.

2. $cases(
	y'' = 0,
	y' (0) = 0, y' (1) = 0
)$

$y = c_1 x + c_2$ --- общее решение. \
$y' (x) = c_1 \
y'(0) = c_1 = 0 \
y'(1) = c_1 = 0$ \
$y(x) = c_2$ --- решение краевой задачи при любом $c_2$.

Вывод из второго примера: краевая задача может иметь бесконечно много решений.

$y' (x) = 2 x$

*Определение*.

/ Простейшая краевая задача: имеет вид:
$ #[(1)] y'' + q(x) y = f(x) $ <l8:eq4> // (1)
$ #[(2)] y(a) = 0, y(b) = 0 $ <l8:eq5> // (2)

На примере простейшей краевой задачи можно изучать все краевые задачи.

*Алгоритм решения задачи @l8:eq4>-<l8:eq5> /*(1)-(2)*/*.

1. Попробуем решить уравнение <l8:eq4>. Это не всегда возможно, но бывает такое, что можно.

2. Подставляем в @l8:eq6 /* (3) */ в <l8:eq5> /* (2) */:
$
cases(
	c_1 phi_1 (a) + c_2 phi_2 (a) + y_ч (a) = 0,
	c_1 phi_1 (b) + c_2 phi_2 (b) + y_ч (b) = 0
) #[ --- линейная алгебраическая система относительно $c_1$ и $c_2$]
$ <l8:eq7> /* (4) */

3. Вычисляем определитель системы @l8:eq7

$
  Delta = mat(delim: "|",
	phi_1 (a), phi_2 (a);
	phi_1 (b), phi_2 (b)
  )
$


#underline[1 случай]. $Delta != 0$ $=>$ @l8:eq7 /*(4)*/ имеет единственное решение.  В этом случае \
$y(x) = c_1 dot phi_1 (x) + c_2 y (y) + y_ч (x)$ --- единственное решение @l8:eq4 -- @l8:eq5.

#undeline[2 случай]. $Delta = 0$ $=>$ возникает 2 подслучая.

2.1. Система имеет бесконечно много решений. В этом случае @l8:eq4 -- @l8:eq5 имеет бесконечно много решений
2.2. Система не имеет решений. В этом случае @l8:eq4 -- @l8:eq5 не имеет ни одного решения.

*Следствие*. Рассмотрим краевые задачи @l8:eq4 -- @l8:eq5. Введём в рассмотрение соответствующую однородную краевую задачу.

*Доказательство*:

Применим наш алгоритм к решению задачи @l8:eq8/*(5)*/.

Решаем @l8:eq8/*(5)*/. Получаем общее решение в виде \
$y = c_1 phi_1 + c_2 phi_2 (x)$, где $phi_1 (x), phi_2 (x)$ --- ф. с. р. уравнения @l8:eq8/*(5)*/.

Подставляем эту формулу в краевые условия
$
cases(
	c_1 phi_1 (a) + c_2 phi_2 (a) = 0,
	c_1 phi_1 (b) + c_2 phi_2(b) = 0
) #[ --- линейная алгебраическая система относительно $c_1$ и $c_2$]
$<l8:eq9>/*(6)*/

$Delta = mat(delim: "|",
	phi_1 (a), phi_2 (a);
	phi_1 (b), phi_2 (b)
) != 0$, так как в противном случае и тогда задача <l8:eq8>/*(5)*/ будет иметь бесконечно много решений.

Теперь, согласно алгоритму, исходная задача имеет единственное решение: $Delta != 0 =>$ система @l8:eq7/*(4)*/ имеет единственное решнеие.

$
  mat(
	a_11 y_1, a_(12) y_2, dots, a_1n y_n, f_1 (x);
	a_21 y_1, a_(22) y_2, dots, a_(2n) y_n, f_2 (x);
	dots, dots, dots, dots, dots;
	a_(n 1) y_1, a_(n 2) y_2, dots, a_(n n) y_n, f_n (x);
  )
$

*Определение*. Частное решение системы @l8:eq10/*(1)*/ --- набор функций $phi_1 (x), dots, phi_n (x)$, т. ч.

$
  phi'_j eq.tripe limits(sum)_(k = 1)^n a_(j k) (x) phi(k) + f_j (x), j = overline(1,n)
$

*Определение*. Линейная система  @l8:eq10/*(1)*/ называется одноролной если $f_1 (x) = dots = f_n (x) = 0$.

*Векторная запись линейной системы*. Обозначим вектор-функцией

$Y (x) = vec(y_1 (x), y_2 (x), dots, y_n (x)), F (x) = vec(f_1 (x), f_2 (x), dots, f_n (x)), A(x) = mat(
	a_11 (x), a_12 (x), dots, a_(1 n) (x);
	a_21 (x), a_22 (x), dots, a_(2 n) (x);
	dots, dots, dots, dots;
	a_(n 1) (x), a_(n 2) (x), dots, a_(n n) (x);
) $

#show math.equation: set align(left)

$
  A(x) Y(x) = 
$


Пусть $Phi (x) = vec(phi_1 (x), phi_2 (x), dots, phi_n (x))$.

Тождества @l8:eq11/*(*)*/ $<=>$ $Phi(x) = A(x) Phi(x) + F(x)$

Это означает, что наша вектор-функция $Phi$ даёт решение системы.

*Теорема 1*. Пусть $Phi_1 (x), dots, Phi_m (x)$ --- решения однородной системы
$
Y' = A(x) Y,
$<l8:eq12>/*(1)*/

$alpha_1, dots, alpha_m$ --- произвольные числа. Тогда функция $Phi (x) = alpha_1 Phi_1 (x) + dots + alpha_m Phi_m (x)$ --- тоже решения @l8:eq12/*(1)*/.

*Доказательство*:

По условию $Phi'_j (x) eq.triple A(x) Phi_j (x), j = overline(1, m)$.

Расмотрим $Phi'(x) = alpha_1 Phi'_1 (x) + dots + alpha_m Phi'_m (x) = alpha_1 A(x) Phi_1 (x) + dots + alpha_m A(x) Phi_m (x) = A(x) (alpha_1 Phi_1 (x) + dots + alpha_m Phi_m (x)) = A(x) Phi(x)$.

Таким образом, $Phi' (x) eq.triple A(x) Phi(x) => Phi(x)$ --- решение @l8:eq12.

@l8:eq11 $/*(*)*/ <=> cases(
	Y; = A(x) Y + F(x),
	Y(x_0) = Y^0 #[ --- начальное условие]
)$

*Определение*. Пусть $Phi_1 (x), dots, Phi_m (x)$ --- векторная функция разм-ти $n$ опред.

эти векторные функции линейно зависимы на $[a, b]$, если $exists alpha_1, dots, alpha_m$ --- числа, не все равные 0, так что
$
  alpha_1 Phi_1 (x) + dots + alpha_m Phi_m (x) eq.triple overline(0) space spcae forall x in [a, b]
$

*Определение*. Вектор-функция $Phi_1 (x), dots, Phi_m (x)$ называются *линейно независимыми* на $[a, b]$, если
$
  alpha-1 Phi_1 (x) + dots + alpha_m Phi_m (x) eq.triple vec(0) <=> alpha_1 = dots = alpha_m = 0
$